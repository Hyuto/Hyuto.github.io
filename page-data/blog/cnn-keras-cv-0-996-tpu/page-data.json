{"componentChunkName":"component---src-templates-blog-post-js","path":"/blog/cnn-keras-cv-0-996-tpu/","result":{"data":{"site":{"siteMetadata":{"title":"Hyuto's Blog"}},"mdx":{"id":"a55f602c-e16f-5bd5-9f84-efe35824fb94","excerpt":"This notebook is basically my notebook run on  kaggle  so if you want to try\nand run the code with same environment as mine go to link bellow. Kaggle Notebookâ€¦","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"MNIST Digit Classifier Using Keras, Tensorflow, and TPU\",\n  \"date\": \"2020-08-25T22:56:36\",\n  \"description\": \"Building MNIST Digit Classifier Model Using Keras, Tensorflow, and TPU\",\n  \"lang\": \"en\",\n  \"tags\": \"classification, tensorflow, tpu, image, python\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"This notebook is basically my notebook run on \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.kaggle.com/\"\n  }, \"kaggle\"), \" so if you want to try\\nand run the code with same environment as mine go to link bellow.\"), mdx(\"p\", null, \"Kaggle Notebook : \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.kaggle.com/wahyusetianto/cnn-keras-cv-0-996-tpu\"\n  }, \"CNN Keras CV - 0.996 [TPU]\")), mdx(\"p\", null, \"P.S. Don't forget to \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"upvote\"), \" if you like it \\uD83D\\uDE0A.\"), mdx(\"h2\", {\n    \"id\": \"overview\"\n  }, \"Overview\"), mdx(\"p\", null, \"This kernel is on purpose to build model for MNIST digits dataset. In this kernel we're gonna do some preprocessing then make augmentation datagen so our model didn't train on the same image data, then at each of our model(here we use 15 folds so there will be 15 models) to make prediction for test dataset and by the end we're gonna do ensembles for the prediction.\"), mdx(\"h2\", {\n    \"id\": \"web-app\"\n  }, \"Web App\"), mdx(\"p\", null, \"You can visit my web app for the live prediction by the best model trained on this kernel run on Tensorflow.js \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://hyuto.github.io/showcase/digit-recognizer/\"\n  }, \"Digit Recognizer\"), \".\"), mdx(\"h2\", {\n    \"id\": \"train-on-tpu\"\n  }, \"Train on TPU!!\"), mdx(\"p\", null, \"why? Because it's \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"faster\"), \". While people usually train on GPU for image related things, in this notebook we try to do things on TPU and see how it affect the Accuracy.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"import random\\nimport numpy as np\\nimport pandas as pd\\nfrom timeit import default_timer\\nfrom sklearn.model_selection import KFold\\n\\n# Plot\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# Tensorflow and Keras\\nimport tensorflow as tf\\nfrom tensorflow import keras\\nimport tensorflow.keras.backend as K\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.models import Sequential, load_model\\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D\\nfrom tensorflow.keras.layers import MaxPool2D, BatchNormalization\\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\\n\\nprint(f'Using Tensorflow Version : {tf.__version__}')\\nprint(f'Using Keras Version      : {keras.__version__}')\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"Using Tensorflow Version : 2.2.0\\nUsing Keras Version      : 2.3.0-tf\\n\")), mdx(\"h2\", {\n    \"id\": \"load-the-data\"\n  }, \"Load the Data\"), mdx(\"p\", null, \"Load the MNIST data\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"train = pd.read_csv('../input/digit-recognizer/train.csv')\\ntest = pd.read_csv('../input/digit-recognizer/test.csv')\\ntrain.head()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"5 rows \\xD7 785 columns\\n\")), mdx(\"h2\", {\n    \"id\": \"preprocess\"\n  }, \"Preprocess\"), mdx(\"h3\", {\n    \"id\": \"specifying-x-and-y\"\n  }, \"Specifying X and y\"), mdx(\"p\", null, \"for y we need to encode to one hot vector. In keras we have function \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"to_categorical\"), \" for this.\"), mdx(\"p\", null, \"Example :\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"y = [1, 0, 4]\\nto_categorical(y)\\n\\n# Output:\\n[\\n [0,1,0,0,0], # 1\\n [1,0,0,0,0], # 0\\n [0,0,0,0,1], # 4\\n]\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Specifying X and y\\nX = train.drop(['label'], axis = 1)\\ny = to_categorical(train['label'].values) # To Categorical y\\n\")), mdx(\"h3\", {\n    \"id\": \"normalizing-images\"\n  }, \"Normalizing Images\"), mdx(\"p\", null, \"Data normalization is an important step to ensures that each input parameter (pixel, in this case) has a similar data distribution. This makes convergence faster while training the network.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Normalize\\nX = X / 255.0\\nX_test = test / 255.0\\n\")), mdx(\"h3\", {\n    \"id\": \"reshape\"\n  }, \"Reshape\"), mdx(\"p\", null, \"Train and test images (28px x 28px) has been stock into pandas. Dataframe as 1D vectors of 784 values. We reshape all data to 28x28x1 3D matrices.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Reshape Array\\nX = X.values.reshape(-1, 28, 28, 1)\\nX_test = X_test.values.reshape(-1, 28, 28, 1)\\n\")), mdx(\"h3\", {\n    \"id\": \"lets-take-a-look-at-our-data\"\n  }, \"Let's take a look at our data\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"fig, axes = plt.subplots(ncols=10, nrows=5, figsize = (13, 7))\\ninit = 0\\nfor i in range(5):\\n    j = 0\\n    for k in range(2):\\n        ind = random.choices(train.label[train.label == init].index, k = 5)\\n        init += 1\\n        while j < len(ind):\\n            axes[i, k*5 + j].imshow(X[ind[j]][:,:,0], cmap=plt.cm.binary)\\n            axes[i, k*5 + j].axis('off')\\n            j += 1\\n        j = 0\\nfig.tight_layout()\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"630px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/0995ecc1e7de346086519e39d71607ea/cc488/output_12_0.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"52.53164556962025%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAADBElEQVQozxWS3VPiVgDF869Xtzq7XTu7+1B37IMz4kpgpUZnG7aZKhgRhQQDCIR8EGgwueTrkhByEyaB28n775w558wh2u32axiGZLPZHGRZVqEoqj+fz8nRaCQlSfK93W4rcRwXJ5OJGEVRxfO81+VyWXIcp79er/+CEA4AAH8jhB4URekTz8/PQJblnzzPW/1+/+7k5MS0bfsnx3EQQvhvo9HwN5tNVZZlZ7Va3em6DrbbLaPrupll2Z2iKAuEUFNRlKHruoAQBKEEADjgeb4MAPggSRIZx/GBqqoVjPH7l5eXq81mcyAIwnfLsj64rktijA91XSdN0/wtDMOSqqqfkiT5M9cSxWIxGo/HD6enp8iyrNbV1VVo2/YDTdOp4zhNkiS3q9WKvbi42Hie15pOp+s4jhvD4TDMeZ7nc32/0+noPM+viSRJClEU7bmue75arQ4AAGfb7XYPQlhcLBbvDMMoxXH8i67rFxjjg5xHCO0HQXCWN/F9v4Ax/mhZ1h+maZ4RNE3jKIo6giDgbrf7enx8jCVJ6pTLZRwEQY9hGAwh5HNusVi8DodD7HmeMBqNsGmag9lshgEAqiiKHsdxmJhOp+e73W7fNM1v+Tbdbrdg2/a+ruulLMt+dV23nKbp3mQyKZqmeZg32e1278IwLKRpehgEwTfP845Go9GxZVnnBM/zvizLNZIkA9/3H2mahgihWqFQQMvlkm21WglC6I5l2bWmaQ2WZZeaptXH4zFUVfUxf8FgMOh0Op1JvV5fEpqmXWuadsRx3A2E8HOv16PSND2iKIre7XafFEWpRlH0UVXVH0mSfJZl+TqKot8dx6Ewxl8Mw7gxDOPrfD4vvL29XROz2UzDGOem0/V6Td/f36tJklD1ev0tDMMf1WrVsCyLEkXxvyiK6DwJhPCmUqmoDMPQiqJos9ks/yPPsuwkT2j6vl+VJAkEQXBbq9WMNE2rDMO4nucxl5eXMMsymuM4GyF022q1TNd1/6Eoynh6eroVRRE4jvPY6/UGsiwb/wOjpOMVzbCcsQAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"src\": \"/static/0995ecc1e7de346086519e39d71607ea/f058b/output_12_0.png\",\n    \"srcSet\": [\"/static/0995ecc1e7de346086519e39d71607ea/c26ae/output_12_0.png 158w\", \"/static/0995ecc1e7de346086519e39d71607ea/6bdcf/output_12_0.png 315w\", \"/static/0995ecc1e7de346086519e39d71607ea/f058b/output_12_0.png 630w\", \"/static/0995ecc1e7de346086519e39d71607ea/cc488/output_12_0.png 928w\"],\n    \"sizes\": \"(max-width: 630px) 100vw, 630px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"as you can see there some nice & bad hand written digits number at our dataset.\"), mdx(\"h2\", {\n    \"id\": \"data-augmentation\"\n  }, \"Data Augmentation\"), mdx(\"p\", null, \"we currently have about 42000 image data, let's multiply that value by doing some soft augmentation.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"datagen = ImageDataGenerator(rotation_range=10,\\n                             zoom_range = 0.10,\\n                             width_shift_range=0.1,\\n                             height_shift_range=0.1)\\n\")), mdx(\"p\", null, \"let's take a look on our Augmentation datagen\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def AUG_test(X, y):\\n    fig, axes = plt.subplots(1, 5, figsize = (10,5))\\n    axes[0].imshow(X[:,:,0], cmap=plt.cm.binary)\\n    axes[0].set_title('Actual')\\n    axes[0].axis('off')\\n    for i in range(1, 5):\\n        aug, _ = datagen.flow(X.reshape(1,28,28,1), y.reshape(1,10)).next()\\n        axes[i].imshow(aug.reshape(28,28),cmap=plt.cm.binary)\\n        axes[i].set_title('Augmented')\\n        axes[i].axis('off')\\n    fig.tight_layout()\\n    return plt.show()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"AUG_test(X[0], y[0])\\n\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"630px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/710183c6067410e8862ad6a60e749cd2/3d4b6/output_18_0.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"22.78481012658228%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsSAAALEgHS3X78AAABPklEQVQY0zWPwUsCURDG908KokuXDh27RYfskuXfE54CxYuXlA6BmBIqhRt4adNyfT1SWFAQBDVCAtd1ffOLF3aZ+Wa+b+abcbTWifF4fAYcAntKqYTruqnFYnEK7M7n86Nms5kKgiAZhuEBsO95XlIpddHv94+BneFweNJqtS611ucOQLvdRin1DTRtHccx3W7XwkcR+bHA933W67UG3m1dr9f/Nfc2hGEo1WoVJwgC0uk0xpgJ0LBkNpuNPc+z8AH40lpLoVBgu+ylXC5TLBZjIDLG3AGSy+WiTqeDk8lkmM1mVrwAnhuNBnZge+kTsMzn80wm1o/P6XTq12q1P15EbKoMBgNKpdJfzxmNRr513mw2j0Cm1+t1V6vV6/aa6+Vy6VYqlQ7wYYy5BW4sFpFXEbFvXEVR9CYiL9bwF7WcWuUXOXHlAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"src\": \"/static/710183c6067410e8862ad6a60e749cd2/f058b/output_18_0.png\",\n    \"srcSet\": [\"/static/710183c6067410e8862ad6a60e749cd2/c26ae/output_18_0.png 158w\", \"/static/710183c6067410e8862ad6a60e749cd2/6bdcf/output_18_0.png 315w\", \"/static/710183c6067410e8862ad6a60e749cd2/f058b/output_18_0.png 630w\", \"/static/710183c6067410e8862ad6a60e749cd2/3d4b6/output_18_0.png 712w\"],\n    \"sizes\": \"(max-width: 630px) 100vw, 630px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"h2\", {\n    \"id\": \"build-cnn-model\"\n  }, \"Build CNN Model\"), mdx(\"p\", null, \"The CNN's in this kernel follow LeNet5's design on \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.kaggle.com/cdeotte\"\n  }, \"Chris Deotte\"), \" kernel \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist\"\n  }, \"here\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def build_model():\\n    model = Sequential()\\n    model.add(Conv2D(32, kernel_size = 3, activation='relu',\\n                     input_shape = (28, 28, 1)))\\n    model.add(BatchNormalization())\\n    model.add(Conv2D(32, kernel_size = 3, activation='relu'))\\n    model.add(BatchNormalization())\\n    model.add(Conv2D(32, kernel_size = 5, strides=2, padding='same',\\n                     activation='relu'))\\n    model.add(BatchNormalization())\\n    model.add(Dropout(0.4))\\n\\n    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\\n    model.add(BatchNormalization())\\n    model.add(Conv2D(64, kernel_size = 3, activation='relu'))\\n    model.add(BatchNormalization())\\n    model.add(Conv2D(64, kernel_size = 5, strides=2, padding='same',\\n                     activation='relu'))\\n    model.add(BatchNormalization())\\n    model.add(Dropout(0.4))\\n\\n    model.add(Conv2D(128, kernel_size = 4, activation='relu'))\\n    model.add(BatchNormalization())\\n    model.add(Flatten())\\n    model.add(Dropout(0.4))\\n    model.add(Dense(10, activation='softmax'))\\n\\n    model.compile(optimizer=\\\"adam\\\", loss=\\\"categorical_crossentropy\\\",\\n                  metrics=[\\\"accuracy\\\"])\\n\\n    return model\\n\")), mdx(\"h2\", {\n    \"id\": \"detect-and-instantiate-tpu-distribution-strategy\"\n  }, \"Detect and Instantiate TPU Distribution Strategy\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# detect and init the TPU\\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\\ntf.config.experimental_connect_to_cluster(tpu)\\ntf.tpu.experimental.initialize_tpu_system(tpu)\\n\\n# instantiate a distribution strategy\\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Config\\nEPOCHS = 45\\nBATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\\n\")), mdx(\"h2\", {\n    \"id\": \"training\"\n  }, \"Training\"), mdx(\"p\", null, \"Here we use Kfold CV to split our data by 15 and build model at each fold. At the callbacks we use \", mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"math math-inline\"\n  }, \"f(x) = 0.001 \\\\times 0.95^x\"), \" for our LR Scheduler and do Checkpoint at \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"best \", mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"val_acc\")), \" score.\"), mdx(\"p\", null, \"Note that Tensorflow distribution strategy haven't supported \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ImageDataGenerator\"), \" by this \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://github.com/tensorflow/tensorflow/issues/34346\"\n  }, \"issue\"), \" so instead use that at \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"fit_generator\"), \" we just have to extract Augmentation data by looping through and done training by \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"fit\"), \".\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Init\\nscores, History = [], []\\npred = np.zeros(shape = (len(test), 10))\\n\\n# CV\\ncv = KFold(n_splits=15, shuffle = True, random_state = 42)\\nfor fold, (train_index, val_index) in enumerate(cv.split(X)):\\n    start = default_timer()\\n    # Clear Session\\n    K.clear_session()\\n    tf.tpu.experimental.initialize_tpu_system(tpu)\\n\\n    # Splitting\\n    X_train , y_train = X[train_index], y[train_index]\\n    X_val, y_val = X[val_index], y[val_index]\\n\\n    # Augmentation\\n    Train_x, Train_y = None, None\\n    batch = 0\\n    for x_batch, y_batch in datagen.flow(X_train, y_train,\\n                                         batch_size=BATCH_SIZE):\\n        if batch == 0:\\n            Train_x, Train_y = x_batch, y_batch\\n        elif batch >= X.shape[0] // BATCH_SIZE:\\n            break\\n        else:\\n            Train_x = np.concatenate((Train_x, x_batch))\\n            Train_y = np.concatenate((Train_y, y_batch))\\n        batch += 1\\n\\n    # Model\\n    with tpu_strategy.scope():\\n        model = build_model()\\n\\n    # Callbacks\\n    annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x) # LR\\n    sv = ModelCheckpoint(f'Model Fold {fold}.h5', monitor='val_accuracy',\\n                         save_best_only=True, mode='max')\\n\\n    # Training\\n    history = model.fit(Train_x, Train_y, batch_size = BATCH_SIZE,\\n                        epochs = EPOCHS, verbose = 0, callbacks=[annealer, sv],\\n                        steps_per_epoch = X_train.shape[0]//BATCH_SIZE,\\n                        validation_data = (X_val, y_val))\\n    History.append(history.history)\\n\\n    # Load best model\\n    model = load_model(f'Model Fold {fold}.h5')\\n\\n    # Evaluate\\n    score = model.evaluate(X_val, y_val, verbose = 0)[1]\\n    scores.append(score)\\n\\n    # Making Prediction\\n    pred += model.predict(X_test)\\n\\n    time = round(default_timer() - start, 4)\\n    print(f'[INFO] Fold {fold + 1} val_accuracy : {round(score, 4)} - Time : {time} s')\\n\\nprint()\\nprint(f'[INFO] Mean CV scores : {round(sum(scores)/len(scores), 4)}')\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"[INFO] Fold 1 val_accuracy : 0.9961 - Time : 168.7797 s\\n[INFO] Fold 2 val_accuracy : 0.9957 - Time : 173.7161 s\\n[INFO] Fold 3 val_accuracy : 0.9986 - Time : 178.845 s\\n[INFO] Fold 4 val_accuracy : 0.9957 - Time : 174.5829 s\\n[INFO] Fold 5 val_accuracy : 0.9946 - Time : 173.8493 s\\n[INFO] Fold 6 val_accuracy : 0.9979 - Time : 175.585 s\\n[INFO] Fold 7 val_accuracy : 0.9964 - Time : 176.5861 s\\n[INFO] Fold 8 val_accuracy : 0.9968 - Time : 177.6894 s\\n[INFO] Fold 9 val_accuracy : 0.995 - Time : 179.8059 s\\n[INFO] Fold 10 val_accuracy : 0.9943 - Time : 176.4369 s\\n[INFO] Fold 11 val_accuracy : 0.9939 - Time : 182.6052 s\\n[INFO] Fold 12 val_accuracy : 0.9961 - Time : 177.0005 s\\n[INFO] Fold 13 val_accuracy : 0.995 - Time : 180.026 s\\n[INFO] Fold 14 val_accuracy : 0.9954 - Time : 179.1445 s\\n[INFO] Fold 15 val_accuracy : 0.9975 - Time : 175.2097 s\\n\\n[INFO] Mean CV scores : 0.9959\\n\")), mdx(\"p\", null, \"And so we've got really great CV score there. Let's check the Training History.\"), mdx(\"h2\", {\n    \"id\": \"history\"\n  }, \"History\"), mdx(\"div\", {\n    \"className\": \"tabbed\"\n  }, \"\\n  \", mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"630px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/7422a0fae641ba551fdb715a86950450/302a4/val_loss.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.45569620253164%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAAB6klEQVQ4y6WT6XLbMAyE+/7Pl2mnmTpObEuWdVKUeJP6OmTiK/1ZaDArQOAKJBc/tm0jW0qJGOMThhCoqoqmaajruriUkrym1MSIDwHnPVeeH1cyrTXeW7TVxPhF+oXZM3n2EofPXCZR68K5rgkh3gnzR2sdwa/088DV4hZv796GglvaCO6ed9rStS0hhscOI84HZnGhOb5gQsQ6y+rXUpjdmETIxxEiRodCTAS1Kuq6Kt3fCLeUMNYyjzXt20/25z3VNDAukk4PaK24TAOHYUKsK51U9Iumyy4Fp9PpmTCmiDWWufmg3/3i+L6jb2uOh4pDfeHSCY6XE+00Fx+1RAjJOE5oZVm1IT5uOZ9h7nDpBGL3G3Vq8E2F37/Svu2o397xQ4MbWmxfE9oTrs1YMR//YLUipvSw5W3D5i3Pgu5jz9icmcaJrukZ63e61xfmpkUeT4yHM2JYmMeJZRRoKQnelKaeZGONwbgVoUbMuuD1gl0EVgqMNqyjQA0dS98hhwEjJ8wqUKIlOkP4TqiNIeVnSyxWYkKOIyZa/OaxUWOdLj91waDtijES7RTO2387zMIO/lO41ltccEU6zjuMM0Xsyip89CUXiuBTWet9uN/y4+j54G9TkW6YbhPyHb2/1z+N3jX4X8s8fwHNYfM7HIlj8gAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"validation loss\",\n    \"title\": \"validation loss\",\n    \"src\": \"/static/7422a0fae641ba551fdb715a86950450/f058b/val_loss.png\",\n    \"srcSet\": [\"/static/7422a0fae641ba551fdb715a86950450/c26ae/val_loss.png 158w\", \"/static/7422a0fae641ba551fdb715a86950450/6bdcf/val_loss.png 315w\", \"/static/7422a0fae641ba551fdb715a86950450/f058b/val_loss.png 630w\", \"/static/7422a0fae641ba551fdb715a86950450/40601/val_loss.png 945w\", \"/static/7422a0fae641ba551fdb715a86950450/302a4/val_loss.png 1080w\"],\n    \"sizes\": \"(max-width: 630px) 100vw, 630px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n  \", mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"630px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/db083aad0563651af90980c4e8ae20ae/302a4/val_accuracy.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"66.45569620253164%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABvklEQVQ4y6WTfW/bIBCH+/2/1/6vlqzNqrROHWNTNzZ2/AIY8DPZmb1kq6pNOwkh7uDh7vhxN44jk4UQ8N6vYzKlFEmSkOc5QghkJpFSrnuC/3Vm4dwtsL7v1+DgB6yzs18Pmt52OO/Qg6E1DdYNc8z6YU3EOXcL1EYTxoANlqavZ6AJlt5pjLOoqqY4lVRlRVXX1FWJqgvObYWzw1rVCrTGoE1LISV921PKE+9RTHmUiOeEUki65IU2OdIcj9THhDKNOb1G6LPCh6nk8QpoLUWakWy3iO1X5GaD2n0jftzwdP+FU/ZEkew57B+QMqJMXxCHHad4h+kafAhXGY4jRhvqvCJ9vCc/PCOi7+yTPbGMyfN3RPKCUA2yUhSlQrWat6Ihywt64wh/lGwH+ipHRA9kqiBTJXlV4kbQNnCuW856YKrMmECYE4H6rGm7Du9/exRjLZV6pcgjpm5YH+CihLk3zgbGn326uC6z7luyNL19lElDxhicNzRdO9+8+D8bk02tepPyVjYTXWs9X9oYz7+YtoY0yz7QodZzH7Ud5uAi1s/mOZGuJRWCYQFef71pY/gL0Efgm6+3LP7XJs4PIm3zZreLK4cAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"validation accuracy\",\n    \"title\": \"validation accuracy\",\n    \"src\": \"/static/db083aad0563651af90980c4e8ae20ae/f058b/val_accuracy.png\",\n    \"srcSet\": [\"/static/db083aad0563651af90980c4e8ae20ae/c26ae/val_accuracy.png 158w\", \"/static/db083aad0563651af90980c4e8ae20ae/6bdcf/val_accuracy.png 315w\", \"/static/db083aad0563651af90980c4e8ae20ae/f058b/val_accuracy.png 630w\", \"/static/db083aad0563651af90980c4e8ae20ae/40601/val_accuracy.png 945w\", \"/static/db083aad0563651af90980c4e8ae20ae/302a4/val_accuracy.png 1080w\"],\n    \"sizes\": \"(max-width: 630px) 100vw, 630px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"h2\", {\n    \"id\": \"ensembleing-predictions\"\n  }, \"Ensembleing Predictions\"), mdx(\"p\", null, mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"np.argmax\"), \" through the prediction to get the number of class\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"pred = np.array([np.argmax(x) for x in pred])\\n\\n# Countplot Prediction\\nplt.figure(figsize = (7,7))\\nsns.countplot(pred)\\nplt.title('Countplot of Predictions')\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"451px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/331531bb65cc6908f464a6e2e9da132e/38070/output_30_0.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"94.9367088607595%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsSAAALEgHS3X78AAAD10lEQVQ4y62Ta0yTZxiG3wnq4lTAP8KSRV1iMv4s2yKJLNkhTA5CoQUMjE4UdbGwEEB0HLYsYGlhC4eICqKlFCi0wEI4CAj0a3WTmhFhBzqzgG1tRmCljQu0/Vpo+3338nVucT8Wd+BJnvfnlevO/bzEYrEQAOSHOUOI6eH8i78A4Uvc/mzZq9FQLxUUFLyek5NzuLCw8LX8/Pw3RCLRIZFIFNXf379veXl578LCQoTRaAw3m80RBoNhDwcL4oB2u73Vs+HF6sNv3GumGS+9vu6ladrndDgYh8PBuly0n6Zpv8vlYpxOJ+um3T6Px+N1u93crnvW12G32yfJ0ODANkLIdufqr0oAsMqFfnt3Lv7lMNzj9bhvE9uaO5gzNC8uK2xuwNqW7V3q/JCdtc+zi4vz7Nr9Gdb1eJWlnRssyzKs3+9n4QVrMT1iFe3t7OqqjfX5nL5l2gOjza4lGY2TwedtIMekqnZBwzhW2k76jK1ZeLcrFS03Psb3MbEYvzwMdeO9gIrX4cHijVno+yh8UiHGV3cqob+b5+fduovkIY2ORGWXc5G38S92dvJqx2ANAIWIV78Pmbwcc0d5GKkbgOrSNAavNUIjV2Cp+TvoVZOQfFEPSnMBWk2mnz+hh2CY0hHRiDUoukxJ0qTqtuTaMc7QyxnGqTN/ByYkYaR+AH1Ns7hSlIuuigqsyB9gSjUBcU0ttFQpbms/8Kf8AXynoGErISRYIFZ2JP9pmIU41V+BvVdncb2sCL3SalhlhqeAJdBRQn/K+BT4HDAy4cTzPwEktaqrnfcMYEtJIXokUlhlP/49cFf4voj0obVAZN7Tkf8r8EB04g5CyA7BRWVnct2t/2+oBrZEnZORNMkmGR4+XcGdTVCquOuZpfwjYEzx1a0IlNK9OaXkjq4EHbk0RdIkKsWmRE5v1ARzd8iv7FA+KWXD2JrFxKoyGJm8jJlLSGJG6gaY3iszTEtJAdMjkTBWmYGZ6p5gxDW1DEWVMDpK6A0AhyiKZHfOBb1ddZOkV/cEWrYpcmCSCwM/pbWtHIajSRitH0Rf07e4XlqIXqkUttYH0KsnUfV5HXTaUtzRCcGfvAfBTe3X5Pw0tpydB+F9KmtIrB54bGk5Pm9ozjC9155ubr52wTgdm2Dur+kxKxv05svFH5k6KipNj5rum7WKYdNnYql5bLTYNDaaYUwaoqy8L0e7yZN5bv+hmJ0HjwjDGk69ueuc4NXQ/SmvhIlyBTtPHXg57ExyTsixxLOh/LeiQ7Li4kPyE86EFZ3I2x0TGx+alxezOzMjMuxgZvaeyOOnX/gNDjTpSlOVscEAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"src\": \"/static/331531bb65cc6908f464a6e2e9da132e/38070/output_30_0.png\",\n    \"srcSet\": [\"/static/331531bb65cc6908f464a6e2e9da132e/c26ae/output_30_0.png 158w\", \"/static/331531bb65cc6908f464a6e2e9da132e/6bdcf/output_30_0.png 315w\", \"/static/331531bb65cc6908f464a6e2e9da132e/38070/output_30_0.png 451w\"],\n    \"sizes\": \"(max-width: 451px) 100vw, 451px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"h2\", {\n    \"id\": \"lets-check-some-of-our-prediction\"\n  }, \"Let's check some of our prediction\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"fig, axes = plt.subplots(ncols=10, nrows=5, figsize = (13, 7))\\ninit = 0\\nfor i in range(5):\\n    j = 0\\n    for k in range(2):\\n        ind = random.choices(test.index, k = 5)\\n        init += 1\\n        while j < len(ind):\\n            axes[i, k*5 + j].imshow(X_test[ind[j]][:,:,0], cmap=plt.cm.binary)\\n            axes[i, k*5 + j].set_title(f'Prediction : {pred[ind][j]}', fontsize = 11)\\n            axes[i, k*5 + j].axis('off')\\n            j += 1\\n        j = 0\\nfig.tight_layout()\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"630px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/93510023de4a8aa0b9df3c023f51c209/6295b/output_32_0.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"53.16455696202532%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAADS0lEQVQozxXQa2/bVACA4fwy2KiGJsbaISaE6MQqxIBxGWnG2CQkVIkx2iplg03a1jGE1rJVCNJQGtpG6mLnNDSJ6zRu6pwcH9ttbMeXOL4kduK0/mDUH/BKj94YwzAJlmUv5fP5b3mef4ckye9ardZ5lmV/UBTlAsMwdziOGy0Wi3ckSRqjKGpa1/VzEMIZy7LOAQC+z+fzF3men+I4bjy2u7vLHh4ePqcoymi320/X19d7R0dHSUEQwn6//3Oj0QiiKLqLEAp833+wvb09HA6HSdM0Q9/3kyRJ9jDGT3Vd1x3H+TMmSdJlURTP7+zsXBUE4Wy9Xv/Cdd1TLMtO1mq1EYRQ3DCM0yzLxm3bHuE4LgEhfJXn+QTG+BWapr90HOd1jPFnhmG8GctkMnvtdnthdXVV9X3/CYTQ0XV9liTJwPO8e8vLy76u63MEQXi2bf+UyWT6ruvOEAQxlGV5dmtry2k2m0+y2WyrXC7/EatWqx9gjMd4nv9c1/U3RFGMF4vF1xqNxldBEJypVCrXIYQjsixfxxifoSjqRq/XO8UwzNee550+EVuWdZam6WuCIIzFarVaNQzDhVarpRiGMV+tVi1N02YAAH3Hce6urKz0bNtOptPpbqfTucdxnBcEwXQulxuYpjmzublpMQzzGCEkQwiXTh7eNE3zsqIot13Xfc+yrGlN0y7QND3H8/zbGxsbSUmS3qJpOuk4zkVBEOb6/f4oRVE/mqY5CgCYhRC+KwjC7U6nMxEDAPyl6/o0wzAvOY6bKhQKBcMwEgCAncFgcHN/f7/s+/4NAEA5CIJbEELKdd1JhBCtKEqiVCr95zjO1OLi4st0Op2MEQTxSFXVW6IovlAUZbJSqaR6vd6VQqGwqmna1Xq9vhIEwccAgL/DMPwUY/yPqqofIoQyURRdIUkyJctyfGlp6QVJkt/EcrncrKIo1/L5/CNN0z4hSfLXg4ODSzzPL6iqOpFOp581m833CYJ45nneBEJosdvtjgMAfk+lUuMIod8ajcZHe3t78xjjeCyVSjW73e5yqVQaCILwvFwuR2EY3hdFMTo+Pp7PZrORZVkPGYaJTNP8RZKkyLbt+2traxHG+AFFUVG73T7p+vV6/d//Ac59rqkeFQn6AAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"src\": \"/static/93510023de4a8aa0b9df3c023f51c209/f058b/output_32_0.png\",\n    \"srcSet\": [\"/static/93510023de4a8aa0b9df3c023f51c209/c26ae/output_32_0.png 158w\", \"/static/93510023de4a8aa0b9df3c023f51c209/6bdcf/output_32_0.png 315w\", \"/static/93510023de4a8aa0b9df3c023f51c209/f058b/output_32_0.png 630w\", \"/static/93510023de4a8aa0b9df3c023f51c209/6295b/output_32_0.png 919w\"],\n    \"sizes\": \"(max-width: 630px) 100vw, 630px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"looks like our models really doing good for predicting test data\"), mdx(\"h2\", {\n    \"id\": \"conclusions\"\n  }, \"Conclusions\"), mdx(\"p\", null, \"Based on our CV scores it's lower than \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.kaggle.com/cdeotte\"\n  }, \"Chris Deotte\"), \" kernel \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist\"\n  }, \"here\"), \" with 0.99757 on validation accuracy on the same model architecture. So here's the point:\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"GPU do better job in this task \", \"[Expected]\", \" while TPU give you lower accuracy but faster since we'd train 15 CNNs model on 45 epochs in less than one hour.\")), mdx(\"h2\", {\n    \"id\": \"references\"\n  }, \"References\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"25 Million Images! \", \"[0.99757]\", \" MNIST \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.kaggle.com/cdeotte/25-million-images-0-99757-mnist\"\n  }, \"Link\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Introduction to CNN Keras - 0.997 (top 6%) \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6\"\n  }, \"Link\"))));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"MNIST Digit Classifier Using Keras, Tensorflow, and TPU","tags":"classification, tensorflow, tpu, image, python","date":"August 25, 2020","description":"Building MNIST Digit Classifier Model Using Keras, Tensorflow, and TPU"},"headings":[{"depth":2,"value":"Overview"},{"depth":2,"value":"Web App"},{"depth":2,"value":"Train on TPU!!"},{"depth":2,"value":"Load the Data"},{"depth":2,"value":"Preprocess"},{"depth":3,"value":"Specifying X and y"},{"depth":3,"value":"Normalizing Images"},{"depth":3,"value":"Reshape"},{"depth":3,"value":"Let's take a look at our data"},{"depth":2,"value":"Data Augmentation"},{"depth":2,"value":"Build CNN Model"},{"depth":2,"value":"Detect and Instantiate TPU Distribution Strategy"},{"depth":2,"value":"Training"},{"depth":2,"value":"History"},{"depth":2,"value":"Ensembleing Predictions"},{"depth":2,"value":"Let's check some of our prediction"},{"depth":2,"value":"Conclusions"},{"depth":2,"value":"References"}]},"previous":{"fields":{"slug":"/machine-translation-en-jp-seq2seq-tf/"},"frontmatter":{"title":"Machine Translation English to Japanese with Seq2Seq & Tensorflow"}},"next":{"fields":{"slug":"/bdc-satria-data-2020/"},"frontmatter":{"title":"Hoax Classification - BDC Satria Data 2020"}}},"pageContext":{"id":"a55f602c-e16f-5bd5-9f84-efe35824fb94","previousPostId":"7f21028f-9bf6-571e-b48c-fc618438fb1a","nextPostId":"7e594816-4898-5be2-a94f-640e6ea230c6"}},"staticQueryHashes":["1503043946","3274528899","3764592887"]}