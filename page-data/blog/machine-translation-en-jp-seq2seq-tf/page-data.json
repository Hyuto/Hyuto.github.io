{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/blog/machine-translation-en-jp-seq2seq-tf/",
    "result": {"data":{"site":{"siteMetadata":{"title":"Hyuto's Blog"}},"mdx":{"id":"a36bb6fb-4781-55a5-bedd-1072d52d7875","excerpt":"Hello guys, lately i've been studying about machine translation and give it a try. Most of code in this notebook is based on tensorflow tutorial on theirâ€¦","body":"var _excluded = [\"components\"];\n\nfunction _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Machine Translation English to Japanese with Seq2Seq & Tensorflow\",\n  \"date\": \"2020-08-19T08:51:25\",\n  \"description\": \"Machine Translation English to Japanese using Seq2Seq & Tensorflow 2\",\n  \"lang\": \"en\",\n  \"tags\": \"nlp, nmt, tensorflow, seq2seq, python\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, _excluded);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"Hello guys, lately i've been studying about machine translation and give it a try.\"), mdx(\"p\", null, \"Most of code in this notebook is based on tensorflow tutorial on their website\\n\", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt\"\n  }, \"TensorFlow Addons Networks : Sequence-to-Sequence NMT with Attention Mechanism\"), \".\"), mdx(\"p\", null, \"This notebook is basically my notebook run on \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.kaggle.com/\"\n  }, \"kaggle\"), \" so if you want to\\ntry and run the code with same environment as mine go to link bellow.\"), mdx(\"p\", null, \"Kaggle Notebook : \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.kaggle.com/wahyusetianto/machine-translation-en-jp-seq2seq-tf\"\n  }, \"Machine Translation EN-JP Seq2Seq Tensorflow\")), mdx(\"p\", null, \"P.S. Don't forget to \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"upvote\"), \" if you like it \\uD83D\\uDE0A.\"), mdx(\"h2\", {\n    \"id\": \"overview\"\n  }, \"Overview\"), mdx(\"p\", null, \"So in this notebook we're going to build English to Japanese machine translation, Japanese text\\ncontains lots of unique words because they have 3 type of it:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Kanji\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Katakana\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Hiragana\")), mdx(\"p\", null, \"that's the interesting part of it and so it'll be little complicated to process.\\nSo let's get started.\"), mdx(\"h2\", {\n    \"id\": \"install-some-tools\"\n  }, \"Install some tools\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Sacreblue for calculate BLEU score\"), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"Googletrans => Google Translate for testing some sentences later\")), mdx(\"p\", null, \"Note : You can use NLTK for calculating BLEU score \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.nltk.org/_modules/nltk/translate/bleu_score.html\"\n  }, \"documentation\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"!pip -q install sacrebleu\\n!pip -q install googletrans\\n!pip -q install tensorflow-addons --upgrade\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"import random, re, string, itertools, timeit, sacrebleu\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom tqdm.notebook import tqdm\\nfrom IPython.display import display, clear_output\\nfrom sklearn.model_selection import train_test_split\\n\\n# Tensorflow & Keras\\nimport tensorflow as tf\\nimport tensorflow_addons as tfa\\nimport tensorflow.keras.backend as K\\nfrom tensorflow.keras.layers import Input, Dense, LSTM, LSTMCell\\nfrom tensorflow.keras.layers import Embedding, Bidirectional\\nfrom tensorflow.keras.models import Model\\nfrom tensorflow.keras.preprocessing.text import Tokenizer\\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\\nfrom tensorflow.keras.optimizers import Adam\\n\\n# Japanese Word Tokenizer\\nfrom janome.tokenizer import Tokenizer as janome_tokenizer\\n\\nplt.style.use('seaborn-pastel')\\n\")), mdx(\"h2\", {\n    \"id\": \"dataset\"\n  }, \"Dataset\"), mdx(\"p\", null, \"Here we use 55463 en-jp corpus from \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"http://www.manythings.org/bilingual/\"\n  }, \"ManyThings.org Bilingual Sentence Pairs\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Download Data & Unzip Data\\n!wget http://www.manythings.org/anki/jpn-eng.zip\\n!unzip jpn-eng.zip\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"--2020-08-19 01:52:31--  http://www.manythings.org/anki/jpn-eng.zip\\nResolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 172.67.173.198, ...\\nConnecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 2303148 (2.2M) [application/zip]\\nSaving to: \\u2018jpn-eng.zip\\u2019\\n\\njpn-eng.zip         100%[===================>]   2.20M  9.70MB/s    in 0.2s\\n\\n2020-08-19 01:52:32 (9.70 MB/s) - \\u2018jpn-eng.zip\\u2019 saved [2303148/2303148]\\n\\nArchive:  jpn-eng.zip\\n  inflating: jpn.txt\\n  inflating: _about.txt\\n\")), mdx(\"p\", null, \"Load data to memory.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"data = []\\n\\nf1 = open('./jpn.txt', 'r')\\ndata += [x.rstrip().lower().split('\\\\t')[:2] for x in tqdm(f1.readlines())]\\nf1.close()\\n\\nprint(f'Loaded {len(data)} Sentences')\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"Loaded 53594 Sentences\\n\")), mdx(\"h2\", {\n    \"id\": \"text-preprocessing\"\n  }, \"Text Preprocessing\"), mdx(\"h3\", {\n    \"id\": \"handling-misspell-words--clearing-punctuation\"\n  }, \"Handling misspell words & Clearing Punctuation\"), mdx(\"p\", null, \"we're gonna change the misspell words in english sentences and clearing punctuation from text.\"), mdx(\"p\", null, \"\\\"aren't my english bad?\\\" -> \\\"are not my english bad\\\"\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"mispell_dict = {\\n    \\\"aren't\\\" : \\\"are not\\\",\\n    \\\"can't\\\" : \\\"cannot\\\",\\n    \\\"couldn't\\\" : \\\"could not\\\",\\n    \\\"didn't\\\" : \\\"did not\\\",\\n    \\\"doesn't\\\" : \\\"does not\\\",\\n    \\\"don't\\\" : \\\"do not\\\",\\n    \\\"hadn't\\\" : \\\"had not\\\",\\n    \\\"hasn't\\\" : \\\"has not\\\",\\n    \\\"haven't\\\" : \\\"have not\\\",\\n    \\\"he'd\\\" : \\\"he would\\\",\\n    \\\"he'll\\\" : \\\"he will\\\",\\n    \\\"he's\\\" : \\\"he is\\\",\\n    \\\"i'd\\\" : \\\"i would\\\",\\n    \\\"i'd\\\" : \\\"i had\\\",\\n    \\\"i'll\\\" : \\\"i will\\\",\\n    \\\"i'm\\\" : \\\"i am\\\",\\n    \\\"isn't\\\" : \\\"is not\\\",\\n    \\\"it's\\\" : \\\"it is\\\",\\n    \\\"it'll\\\":\\\"it will\\\",\\n    \\\"i've\\\" : \\\"i have\\\",\\n    \\\"let's\\\" : \\\"let us\\\",\\n    \\\"mightn't\\\" : \\\"might not\\\",\\n    \\\"mustn't\\\" : \\\"must not\\\",\\n    \\\"shan't\\\" : \\\"shall not\\\",\\n    \\\"she'd\\\" : \\\"she would\\\",\\n    \\\"she'll\\\" : \\\"she will\\\",\\n    \\\"she's\\\" : \\\"she is\\\",\\n    \\\"shouldn't\\\" : \\\"should not\\\",\\n    \\\"that's\\\" : \\\"that is\\\",\\n    \\\"there's\\\" : \\\"there is\\\",\\n    \\\"they'd\\\" : \\\"they would\\\",\\n    \\\"they'll\\\" : \\\"they will\\\",\\n    \\\"they're\\\" : \\\"they are\\\",\\n    \\\"they've\\\" : \\\"they have\\\",\\n    \\\"we'd\\\" : \\\"we would\\\",\\n    \\\"we're\\\" : \\\"we are\\\",\\n    \\\"weren't\\\" : \\\"were not\\\",\\n    \\\"we've\\\" : \\\"we have\\\",\\n    \\\"what'll\\\" : \\\"what will\\\",\\n    \\\"what're\\\" : \\\"what are\\\",\\n    \\\"what's\\\" : \\\"what is\\\",\\n    \\\"what've\\\" : \\\"what have\\\",\\n    \\\"where's\\\" : \\\"where is\\\",\\n    \\\"who'd\\\" : \\\"who would\\\",\\n    \\\"who'll\\\" : \\\"who will\\\",\\n    \\\"who're\\\" : \\\"who are\\\",\\n    \\\"who's\\\" : \\\"who is\\\",\\n    \\\"who've\\\" : \\\"who have\\\",\\n    \\\"won't\\\" : \\\"will not\\\",\\n    \\\"wouldn't\\\" : \\\"would not\\\",\\n    \\\"you'd\\\" : \\\"you would\\\",\\n    \\\"you'll\\\" : \\\"you will\\\",\\n    \\\"you're\\\" : \\\"you are\\\",\\n    \\\"you've\\\" : \\\"you have\\\",\\n    \\\"'re\\\": \\\" are\\\",\\n    \\\"wasn't\\\": \\\"was not\\\",\\n    \\\"we'll\\\":\\\" will\\\",\\n    \\\"didn't\\\": \\\"did not\\\",\\n    \\\"tryin'\\\":\\\"trying\\\"\\n}\\n\\nmispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\\n\\ndef preprocess(text) -> str:\\n    def replace(match):\\n        return mispell_dict[match.group(0)]\\n\\n    text = mispell_re.sub(replace, text)\\n    return text\\n\")), mdx(\"p\", null, \"Japanese words have their own punctuation like \\u3010this\\u3011\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Adding Japanese Punctuation\\nstring.punctuation += '\\u3001\\u3002\\u3010\\u3011\\u300C\\u300D\\u300E\\u300F\\u2026\\u30FB\\u303D\\uFF08\\uFF09\\u301C\\uFF1F\\uFF01\\uFF61\\uFF1A\\uFF64\\uFF1B\\uFF65'\\n\\nCP = lambda x : x.translate(str.maketrans('', '', string.punctuation))\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"data = [x for x in data if len(x) == 2]\\n\\neng_data = [CP(preprocess(x[0])) for x in data]\\njpn_data = [CP(x[1]) for x in data]\\n\")), mdx(\"h3\", {\n    \"id\": \"segmenting-japanese-sentences\"\n  }, \"Segmenting Japanese Sentences\"), mdx(\"p\", null, \"Unlike english sentence we can tokenize it by splitting words with space just like this,\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"'This is english or i think so'.split()\\n\\nOutput:\\n['This', 'is', 'english', 'or', 'i', 'think', 'so']\\n\")), mdx(\"p\", null, \"but in Japanese we can't do it that way. Here we gonna use Janome Tokenizer to segmenting Japanese\\nsentence and adding space to it so Keras Tokenizer can handle it.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Initialize Janome Tokenizer\\ntoken_jp = janome_tokenizer()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"sample_text = '\\u3053\\u3053\\u3067\\u79C1\\u306F\\u82F1\\u8A9E\\u3067\\u8A71\\u3057\\u3066\\u3044\\u308B'\\n' '.join([word for word in token_jp.tokenize(sample_text, wakati=True) \\\\\\n          if word != ' '])\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"'\\u3053\\u3053 \\u3067 \\u79C1 \\u306F \\u82F1\\u8A9E \\u3067 \\u8A71\\u3057 \\u3066 \\u3044\\u308B'\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Apply to Japanese Sentences\\njpn_data = [' '.join([word for word in token_jp.tokenize(x, wakati=True) \\\\\\n                      if word != ' ']) for x in tqdm(jpn_data)]\\n\")), mdx(\"p\", null, \"For evaluating our model let's split our data.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"eng_train, eng_test, jpn_train, jpn_test = \\\\\\ntrain_test_split(eng_data, jpn_data, test_size = 0.04, random_state = 42)\\n\\nprint(f\\\"Splitting to {len(eng_train)} Train data and \\\\\\n{len(eng_test)} Test data\\\")\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"Splitting to 51450 Train data and 2144 Test data\\n\")), mdx(\"h3\", {\n    \"id\": \"add-bos-and-eos\"\n  }, \"Add BOS and EOS\"), mdx(\"p\", null, \"We put BOS \\\"Begin of Sequence\\\" and EOS \\u201CEnd of Sequence\\\" to help our decoder recognize begin\\nand end of a sequence.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"eng_train = ['bos '+ x + ' eos' for x in eng_train + ['unk unk unk']]\\njpn_train = ['bos '+ x + ' eos' for x in jpn_train + ['unk unk unk']]\\n\\neng_val = ['bos '+ x + ' eos' for x in eng_test]\\njpn_val = ['bos '+ x + ' eos' for x in jpn_test]\\n\")), mdx(\"h2\", {\n    \"id\": \"word-tokenizing\"\n  }, \"Word Tokenizing\"), mdx(\"p\", null, \"Here we use Tokenizer API from Keras to make vocabulary and tokenizing our data\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# English Tokenizer\\nen_tokenizer = Tokenizer(filters='')\\nen_tokenizer.fit_on_texts(eng_train)\\n\\n# Japannese Tokenizer\\njp_tokenizer = Tokenizer(filters='')\\njp_tokenizer.fit_on_texts(jpn_train)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"print(f'English vocab size   :', len(en_tokenizer.word_index) - 3)\\nprint(f'Japanese vocab size  :', len(jp_tokenizer.word_index) - 3)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"English vocab size   : 9646\\nJapanese vocab size  : 14403\\n\")), mdx(\"h2\", {\n    \"id\": \"word-cloud\"\n  }, \"Word Cloud\"), mdx(\"p\", null, \"What comes when doing NLP? It's Word Cloud. Let's do it for our vocab.\"), mdx(\"p\", null, \"Font : \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://www.google.com/get/noto/\"\n  }, \"Google Noto Fonts\"), \" -> Noto Sans CJK JP\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"!wget https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJKjp-hinted.zip\\n!wget https://raw.githubusercontent.com/Hyuto/NMT-TF-Seq2seq-EN-JP/master/Japan.jpg\\n!wget https://raw.githubusercontent.com/Hyuto/NMT-TF-Seq2seq-EN-JP/master/English.png\\n!mkdir font\\n!unzip NotoSansCJKjp-hinted.zip -d ./font\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"--2020-08-19 01:53:52--  https://noto-website-2.storage.googleapis.com/pkgs/NotoSansCJKjp-hinted.zip\\nResolving noto-website-2.storage.googleapis.com (noto-website-2.storage.googleapis.com)... 172.217.204.128, 2607:f8b0:400c:c15::80\\nConnecting to noto-website-2.storage.googleapis.com (noto-website-2.storage.googleapis.com)|172.217.204.128|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 121096772 (115M) [application/zip]\\nSaving to: \\u2018NotoSansCJKjp-hinted.zip\\u2019\\n\\nNotoSansCJKjp-hinte 100%[===================>] 115.49M  53.3MB/s    in 2.2s\\n\\n2020-08-19 01:53:54 (53.3 MB/s) - \\u2018NotoSansCJKjp-hinted.zip\\u2019 saved [121096772/121096772]\\n\\n--2020-08-19 01:53:55--  https://raw.githubusercontent.com/Hyuto/NMT-TF-Seq2seq-EN-JP/master/Japan.jpg\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.200.133\\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.200.133|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 3976 (3.9K) [image/jpeg]\\nSaving to: \\u2018Japan.jpg\\u2019\\n\\nJapan.jpg           100%[===================>]   3.88K  --.-KB/s    in 0s\\n\\n2020-08-19 01:53:55 (46.7 MB/s) - \\u2018Japan.jpg\\u2019 saved [3976/3976]\\n\\n--2020-08-19 01:53:56--  https://raw.githubusercontent.com/Hyuto/NMT-TF-Seq2seq-EN-JP/master/English.png\\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.200.133\\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.200.133|:443... connected.\\nHTTP request sent, awaiting response... 200 OK\\nLength: 303684 (297K) [image/png]\\nSaving to: \\u2018English.png\\u2019\\n\\nEnglish.png         100%[===================>] 296.57K  --.-KB/s    in 0.1s\\n\\n2020-08-19 01:53:56 (2.18 MB/s) - \\u2018English.png\\u2019 saved [303684/303684]\\n\\nArchive:  NotoSansCJKjp-hinted.zip\\n  inflating: ./font/LICENSE_OFL.txt\\n  inflating: ./font/NotoSansCJKjp-Black.otf\\n  inflating: ./font/NotoSansCJKjp-Bold.otf\\n  inflating: ./font/NotoSansCJKjp-DemiLight.otf\\n  inflating: ./font/NotoSansCJKjp-Light.otf\\n  inflating: ./font/NotoSansCJKjp-Medium.otf\\n  inflating: ./font/NotoSansCJKjp-Regular.otf\\n  inflating: ./font/NotoSansCJKjp-Thin.otf\\n  inflating: ./font/NotoSansMonoCJKjp-Bold.otf\\n  inflating: ./font/NotoSansMonoCJKjp-Regular.otf\\n  inflating: ./font/README\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"from wordcloud import WordCloud, ImageColorGenerator\\nfrom PIL import Image\\n\\ndef get_words(arr):\\n    keys = list(arr.keys())\\n    count = list(arr.values())\\n    return ' '.join([x for _,x in sorted(zip(count, keys), reverse = True)][2:])\\n\\ndef transform(arr):\\n    for i in range(len(arr)):\\n        for j in range(len(arr[i])):\\n            if not any(arr[i][j]):\\n                arr[i][j] = np.array([225, 225, 225, 225])\\n    return arr\\n\\nfont_path = './font/NotoSansCJKjp-Light.otf'\\n\\n\\nmask = './English.png'\\nmask = np.array(Image.open(mask))\\nmask = transform(mask)\\nimage_colors = ImageColorGenerator(mask)\\nwords = get_words(en_tokenizer.word_counts).title()\\nwc = WordCloud(background_color=\\\"white\\\", max_words=2000, random_state=42,\\n               width=mask.shape[1], height=mask.shape[0])\\nwc = wc.generate(words)\\nfig1, ax1 = plt.subplots(figsize=(20,15))\\nax1.imshow(wc.recolor(color_func=image_colors), interpolation='bilinear')\\nax1.axis(\\\"off\\\")\\n\\nmask = './Japan.jpg'\\nmask = np.array(Image.open(mask))\\nimage_colors = ImageColorGenerator(mask)\\nwords = get_words(jp_tokenizer.word_counts).title()\\nwc = WordCloud(collocations=False, background_color=\\\"white\\\", mode=\\\"RGBA\\\",\\n               max_words=6000, font_path=font_path, contour_width=1,\\n               scale=5, max_font_size = 50, relative_scaling=0.5,\\n               random_state=42, width=mask.shape[1], height=mask.shape[0])\\nwc = wc.generate(words)\\nfig2, ax2 = plt.subplots(figsize=(20,15))\\nax2.imshow(wc.recolor(color_func=image_colors), interpolation='bilinear')\\nax2.axis(\\\"off\\\")\\n\\nfig1.savefig('WC_English.png')\\nfig2.savefig('WC_Japanese.png')\\nplt.close(fig1)\\nplt.close(fig2)\\n\\n!rm -rf ./font\\n\")), mdx(\"div\", {\n    \"className\": \"tabbed\"\n  }, \"\\n  \", mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"630px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/925d8b9db09014ceb7735de6722223fc/07a9c/WC_English.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"75.31645569620254%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsSAAALEgHS3X78AAACg0lEQVQ4y3WUe1PaUBDF/f5fojPtdOpM31qtDxQReQfQJAQSEhIICAQIT5WQhF8HrA62sH/cvbsze2bvPbtnj7+2XC75z7akdtlL/d5msFj4zD2PMAzx/YCQJU+TGaNml8Dz8D0P7/GR+fQB31sQLBYEfvBav/J7q+MlMRpPqVlNalYL+75Lr9Ul8/WcXCSNKWu0iiWMeA5XNbAydyjnSSYd5xVsDbjZYdsZYDXuKWsWomYhRFLkLrPkErfoQonCp2MK+7+pZ0TUsySp71fULYcw3NFhtzek1uhyq1hkZZPEWZqb4wSxwziVwyiZ9weopzd0FAMzXyZ/LWK2x+vv2QroDkbUzBaKZiOW60iKxfX+KZfvftLNSpg3ecq/rhjIGj3FQDmK0Tdbb5+8Ceg4LpJUparbFAsVBNEgmy2TjwrYxQpWPE/16IpZUWYmV3goyPTkCsFuUmbcNx3seoe61SZ9kSN+lECNCXRiWTo5kV6pSldSsW417EKZe6mynoqtgEN3REfRGZhNnHYfJZpDu0jzpFvoHw+QTxKMW11aJZ22VqcqlKnlxN1j8+AOcSSVodFgvGI8r9BMFQlVHf3DD5InWe4EjXHbwRCr2GqdiqjhBxuksAH4NJkyUHT6moXbaNOIC6T3zximb+l8OyEVKRCLyYjXRUoFDUPSMXSbxS6WZ30XRzMZmk06RpPI5yhnX2IYgkI9mka+SHOXlJHzJWqqQdOyMavmesO2Ak6cAbZSxVAMZMXk/EYikdcQFYuWM+Dh6ZHpbMZoPGYynTCdTXHd4RZSnqO1X+2vt1gwn88JA58g8J8LlkvCIFjf1w0s3wrKG3F4FZblboX5V402md1k+Q9clGHGV8oF9gAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"English WC\",\n    \"title\": \"English WC\",\n    \"src\": \"/static/925d8b9db09014ceb7735de6722223fc/f058b/WC_English.png\",\n    \"srcSet\": [\"/static/925d8b9db09014ceb7735de6722223fc/c26ae/WC_English.png 158w\", \"/static/925d8b9db09014ceb7735de6722223fc/6bdcf/WC_English.png 315w\", \"/static/925d8b9db09014ceb7735de6722223fc/f058b/WC_English.png 630w\", \"/static/925d8b9db09014ceb7735de6722223fc/40601/WC_English.png 945w\", \"/static/925d8b9db09014ceb7735de6722223fc/78612/WC_English.png 1260w\", \"/static/925d8b9db09014ceb7735de6722223fc/07a9c/WC_English.png 1440w\"],\n    \"sizes\": \"(max-width: 630px) 100vw, 630px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \"), \"\\n  \", mdx(\"span\", {\n    parentName: \"div\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"630px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/97526e703f2d47eceebc07ee03968a2e/07a9c/WC_Japanese.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"75.31645569620254%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsSAAALEgHS3X78AAAA70lEQVQ4y62UDQuCMBiE/f+/LaikKCvsO/qiaE6duu1iA0Pi3VzQCzIQ9+yOuxmBGK31Z22f7nvfRKFAEk4cEPlgXahL8bfqfoVKkRtd9p3AdoPMS4jzHeX2ZNcmy0m1/ZalRMM4sukKbDjDazBFNllCHK+QpQi33H6gRIVicwSLE2TxwoL5fA02mqO6Pcmg/MC6QZHuweIFeLIBn6UWzMYJ6sfrd4UmDHG5W5Cxa5QZYJEeoKqabIQT+FHZSAswMJ6ska92NhiqTsEpa6lsOPWTQRals6+9ln1do8ofrtBz9XTI1etQSWDfTyLCn+cNu5Sfjc744QQAAAAASUVORK5CYII=')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Japanese WC\",\n    \"title\": \"Japanese WC\",\n    \"src\": \"/static/97526e703f2d47eceebc07ee03968a2e/f058b/WC_Japanese.png\",\n    \"srcSet\": [\"/static/97526e703f2d47eceebc07ee03968a2e/c26ae/WC_Japanese.png 158w\", \"/static/97526e703f2d47eceebc07ee03968a2e/6bdcf/WC_Japanese.png 315w\", \"/static/97526e703f2d47eceebc07ee03968a2e/f058b/WC_Japanese.png 630w\", \"/static/97526e703f2d47eceebc07ee03968a2e/40601/WC_Japanese.png 945w\", \"/static/97526e703f2d47eceebc07ee03968a2e/78612/WC_Japanese.png 1260w\", \"/static/97526e703f2d47eceebc07ee03968a2e/07a9c/WC_Japanese.png 1440w\"],\n    \"sizes\": \"(max-width: 630px) 100vw, 630px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"now let's transform our train sentences to sequences.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def Sequences(texts, tokenizer):\\n    res = []\\n    for text in texts:\\n        seq = []\\n        for w in text.split():\\n            try:\\n                seq.append(tokenizer.word_index[w])\\n            except:\\n                seq.append(tokenizer.word_index['unk'])\\n        res.append(seq)\\n    return res\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Transform Sentences to Sequences\\ndata_en = en_tokenizer.texts_to_sequences(eng_train)\\ndata_jp = jp_tokenizer.texts_to_sequences(jpn_train)\\n\\nval_en = Sequences(eng_val, en_tokenizer)\\nval_jp = Sequences(jpn_val, jp_tokenizer)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"plt.figure(figsize = (8,8))\\nsns.distplot([len(x) for x in data_en], label='English')\\nsns.distplot([len(x) for x in data_jp], label='Japanese')\\nplt.title('Distribution of Sentences Length')\\nplt.legend()\\nplt.show()\\n\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"490px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/8ce63a24a5b8ffbe5487aa1074fa8a20/41d3c/output_32_0.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"98.10126582278481%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAACwklEQVQ4y6WUW08TQRTH91UTL/XViES8pRD7RELDEwnhkY/gix/AJx8MGm+BGCWR1jbGxAh4ibEQiAoJIBcxxkBSwYhEpCz0Srud3XZ3u213ZnbnmG5boSGGFs/m7Ewyk9/+/2d2DudwODiv13PY5XKf8HoeH3e7+mwDg4PHOjs765ubmx1Op7Opo6OjoaWlpam1tdXe3t5+zul0Nra1tZ33+XxHHz3os3lcHtvAQL/N6/Ue4QCAEwThpWEYlFKKKKWSYRgSxiSt67qSz+dVjLFcnu8aZdMwJCWHU/EkQps8ryOE5iygLMujAADEBCAG1BR5E4OkpCEWjQJC6DsXCAQ4NZN5C8BAp0DylJkAzGTMyv3CBAYmAFBLECH+ssLhAjBPgKZyjBUWC+/ibG8wK4sbrIcxy5eu698sIEKiZVnOM4q0/YHFdfZ3rABGIhFOVTO+wjejCtCwvAOsNiqAsViMU0rAtSTQVaEMZFVD/2n5N2J0KWYVu8JWzcB0unAoACsJRr+GypwDKuR5vmQZwL+N6VxY+3+FqXTaUriU0OloKMpyJtl9grUDkwhZNVyVsnQkFGYyze0AoUZgMBjkFFW1LP9UEB2J8mxdUQ6uMJtROVVVhgoXblEU6LvtDeYXJQAwSz/3/tA9liVJHKUmwLwYouOJDfZJiANh1ddxD1BVlCFsmDAvBsmEsMEm4mGGaNq6stV0CMYYLQH9XGwzyOnZ3LBKMUwmeTYt8jApbMGKtg0AtfUyjPFysduIqTdbmggf4r+UycS6NpUIaFPxrcwPJaJJuqpliZ7BFGuYEo0YRCO0MjElKjUMls1lv3Acxx3qutF15vn0WMOT2ff1V3u7G+8Oui+89s/UXe7pbrxyv9f+bGHh1DXvHfvtpz32j2uf63pfuC7ect9rGl+eOt0//urs9Yc3L40tTpyZmZ89+Qdd/6OoUfpEpAAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"src\": \"/static/8ce63a24a5b8ffbe5487aa1074fa8a20/41d3c/output_32_0.png\",\n    \"srcSet\": [\"/static/8ce63a24a5b8ffbe5487aa1074fa8a20/c26ae/output_32_0.png 158w\", \"/static/8ce63a24a5b8ffbe5487aa1074fa8a20/6bdcf/output_32_0.png 315w\", \"/static/8ce63a24a5b8ffbe5487aa1074fa8a20/41d3c/output_32_0.png 490w\"],\n    \"sizes\": \"(max-width: 490px) 100vw, 490px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"based on the distplot English sentences contains about 20 - 40 words while Japanese have\\nmore wider range.\"), mdx(\"p\", null, \"Let's check their max length\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"max_en = max([len(x) for x in data_en] + [len(x) for x in val_en])\\nmax_jp = max([len(x) for x in data_jp] + [len(x) for x in val_jp])\\n\\nprint(f'Maximum length of English sequences is  {max_en}')\\nprint(f'Maximum length of Japanese sequences is {max_jp}')\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"Maximum length of English sequences is  49\\nMaximum length of Japanese sequences is 54\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Padding Sequences\\ndata_en = pad_sequences(data_en, padding='post', maxlen = max_en)\\ndata_jp = pad_sequences(data_jp, padding='post', maxlen = max_jp)\\n\\nval_en = pad_sequences(val_en, padding='post', maxlen = max_en)\\nval_jp = pad_sequences(val_jp, padding='post', maxlen = max_jp)\\n\")), mdx(\"h2\", {\n    \"id\": \"build--train-model\"\n  }, \"Build & Train Model\"), mdx(\"p\", null, \"Now it's the time brace yourself.\"), mdx(\"p\", null, \"We'll build model based on Seq2seq approaches with Attention optimization.\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"Seq2Seq is a method of encoder-decoder based machine translation that maps an input of sequence to an output of sequence with a tag and attention value. The idea is to use 2 RNN that will work together with a special token and trying to predict the next state sequence from the previous sequence.\")), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"630px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/a5a04f4dc28fd14e1a9c5e883fda9bf5/5a190/seq2seq.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"50.632911392405056%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsTAAALEwEAmpwYAAABeElEQVQoz22R2W7bMBBF/f/fE+SlD0WA5K1tHFuKbS22ZWqjJNJcRdLm0ipKUBvtATHALBd3wFmEe5xzWZZRRkMIPvi56P38fJJkjPGrdeZiQwiL8A/GGGvtbeViOCdgFDBPl+xcNtWW4PL/4nsmc85AWz6t3x6T7bf18gHWzwTHzrnF/dhNvEk73P1cv5awXm3X2SmP0vf0mM/OU59JUrRpj9uyO3S4rvqi7k8dagDMjdFEqAPE7YD3LWoGfGj6lohJ7P0k7s4wLn5lRZI28b5KdyDagTgDyaZcEYorRHZIRvkxxeOmqN7rYY+4s/bTWY2kKlejKE/Fsu9SAKIe7jg51lXsvdXmAvtByBEOSEjZDUgq9Xdto3qBXzWPweEF7F+yzXfU/tAs4ujNXrX3nlIy73jL54dZ61qIrAuYsKu1Uiou9OXqhdTz8b337gP7xSQ2xgAAKKWMETXK8xkLwTljlJJRCsqotVZrzRj7iFRKKYRQSv051W8r8je8hZRFFgAAAABJRU5ErkJggg==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Seq2Seq\",\n    \"title\": \"Seq2Seq\",\n    \"src\": \"/static/a5a04f4dc28fd14e1a9c5e883fda9bf5/f058b/seq2seq.png\",\n    \"srcSet\": [\"/static/a5a04f4dc28fd14e1a9c5e883fda9bf5/c26ae/seq2seq.png 158w\", \"/static/a5a04f4dc28fd14e1a9c5e883fda9bf5/6bdcf/seq2seq.png 315w\", \"/static/a5a04f4dc28fd14e1a9c5e883fda9bf5/f058b/seq2seq.png 630w\", \"/static/a5a04f4dc28fd14e1a9c5e883fda9bf5/5a190/seq2seq.png 800w\"],\n    \"sizes\": \"(max-width: 630px) 100vw, 630px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Config\\nepochs = 7\\nBATCH_SIZE = 64\\nBUFFER_SIZE = len(data_jp)\\nsteps_per_epoch = BUFFER_SIZE//BATCH_SIZE\\nval_steps_per_epoch = len(val_jp) // BATCH_SIZE\\nembedding_dims = 256\\nrnn_units = 1024\\ndense_units = 1024\\nDtype = tf.float32\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def max_len(tensor):\\n    \\\"\\\"\\\"\\n    Get max len in Sequences\\n    \\\"\\\"\\\"\\n    return max( len(t) for t in tensor)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Max Len\\nTx = max_len(data_en)\\nTy = max_len(data_jp)\\n\\n# Vocab\\ninput_vocab_size = len(en_tokenizer.word_index) + 1   # English\\noutput_vocab_size = len(jp_tokenizer.word_index) + 1  # Japanese\\n\\n# Changing to TF data\\ndataset = (tf.data.Dataset.from_tensor_slices((data_en, data_jp))\\n           .shuffle(BUFFER_SIZE)\\n           .batch(BATCH_SIZE, drop_remainder=True)\\n          )\\n\\nval_dataset = (tf.data.Dataset.from_tensor_slices((val_en, val_jp))\\n               .batch(BATCH_SIZE)\\n              )\\n\")), mdx(\"p\", null, \"Let's define our based Seq2Seq Model\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# ENCODER\\nclass EncoderNetwork(tf.keras.Model):\\n    def __init__(self,input_vocab_size,embedding_dims, rnn_units ):\\n        super().__init__()\\n        self.encoder_embedding = Embedding(input_dim=input_vocab_size,\\n                                           output_dim=embedding_dims)\\n        self.encoder_rnnlayer = LSTM(rnn_units,return_sequences=True,\\n                                     return_state=True )\\n\\n# DECODER\\nclass DecoderNetwork(tf.keras.Model):\\n    def __init__(self,output_vocab_size, embedding_dims, rnn_units):\\n        super().__init__()\\n        self.decoder_embedding = Embedding(input_dim=output_vocab_size,\\n                                           output_dim=embedding_dims)\\n        self.dense_layer = Dense(output_vocab_size)\\n        self.decoder_rnncell = LSTMCell(rnn_units)\\n        # Sampler\\n        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\\n        # Create attention mechanism with memory = None\\n        self.attention_mechanism = \\\\\\n            self.build_attention_mechanism(dense_units,None,BATCH_SIZE*[Tx])\\n        self.rnn_cell = self.build_rnn_cell(BATCH_SIZE)\\n        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell,\\n                                                sampler= self.sampler,\\n                                                output_layer = self.dense_layer\\n                                               )\\n\\n    def build_attention_mechanism(self, units, memory, MSL):\\n        \\\"\\\"\\\"\\n        MSL : Memory Sequence Length\\n        \\\"\\\"\\\"\\n        #return tfa.seq2seq.LuongAttention(units, memory = memory,\\n        #                                  memory_sequence_length = MSL)\\n        return tfa.seq2seq.BahdanauAttention(units, memory = memory,\\n                                             memory_sequence_length = MSL)\\n\\n    # wrap decodernn cell\\n    def build_rnn_cell(self, batch_size):\\n        return tfa.seq2seq.AttentionWrapper(self.decoder_rnncell,\\n                                            self.attention_mechanism,\\n                                            attention_layer_size=dense_units)\\n\\n    def build_decoder_initial_state(self, batch_size, encoder_state, Dtype):\\n        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size = batch_size,\\n                                                                dtype = Dtype)\\n        decoder_initial_state = decoder_initial_state.clone(cell_state = encoder_state)\\n        return decoder_initial_state\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Build Model\\nencoderNetwork = EncoderNetwork(input_vocab_size, embedding_dims, rnn_units)\\ndecoderNetwork = DecoderNetwork(output_vocab_size, embedding_dims, rnn_units)\\n\\n# Optimizer\\noptimizer = tf.keras.optimizers.Adam()\\n\")), mdx(\"p\", null, \"Make custom training loop\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"def loss_function(y_pred, y):\\n    #shape of y [batch_size, ty]\\n    #shape of y_pred [batch_size, Ty, output_vocab_size]\\n    sparsecategoricalcrossentropy = SparseCategoricalCrossentropy(from_logits=True,\\n                                                                  reduction='none')\\n    loss = sparsecategoricalcrossentropy(y_true=y, y_pred=y_pred)\\n    mask = tf.logical_not(tf.math.equal(y,0))   #output 0 for y=0 else output 1\\n    mask = tf.cast(mask, dtype=loss.dtype)\\n    loss = mask * loss\\n    loss = tf.reduce_mean(loss)\\n    return loss\\n\\n@tf.function\\ndef train_step(input_batch, output_batch, encoder_initial_cell_state):\\n    # initialize loss = 0\\n    loss = 0\\n    with tf.GradientTape() as tape:\\n        encoder_emb_inp = encoderNetwork.encoder_embedding(input_batch)\\n        a, a_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp,\\n                                                        initial_state = encoder_initial_cell_state)\\n\\n        # [last step activations,last memory_state] of\\n        # encoder passed as input to decoder Network\\n\\n        # Prepare correct Decoder input & output sequence data\\n        decoder_input = output_batch[:,:-1] # ignore eos\\n        # compare logits with timestepped +1 version of decoder_input\\n        decoder_output = output_batch[:,1:] #ignore bos\\n\\n        # Decoder Embeddings\\n        decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\\n\\n        # Setting up decoder memory from encoder output\\n        # and Zero State for AttentionWrapperState\\n        decoderNetwork.attention_mechanism.setup_memory(a)\\n        decoder_initial_state = decoderNetwork.build_decoder_initial_state(BATCH_SIZE,\\n                                                                           encoder_state=[a_tx, c_tx],\\n                                                                           Dtype=tf.float32)\\n\\n        # BasicDecoderOutput\\n        outputs, _, _ = decoderNetwork.decoder(decoder_emb_inp,initial_state=decoder_initial_state,\\n                                               sequence_length=BATCH_SIZE*[Ty-1])\\n\\n        logits = outputs.rnn_output\\n\\n        # Calculate loss\\n        loss = loss_function(logits, decoder_output)\\n\\n    # Returns the list of all layer variables / weights.\\n    variables = encoderNetwork.trainable_variables + decoderNetwork.trainable_variables\\n    # differentiate loss wrt variables\\n    gradients = tape.gradient(loss, variables)\\n\\n    # grads_and_vars \\u2013 List of(gradient, variable) pairs.\\n    grads_and_vars = zip(gradients,variables)\\n    optimizer.apply_gradients(grads_and_vars)\\n    return loss\\n\\n@tf.function\\ndef evaluate(input_batch, output_batch, encoder_initial_cell_state):\\n    loss = 0\\n    encoder_emb_inp = encoderNetwork.encoder_embedding(input_batch)\\n    a, a_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp,\\n                                                    initial_state =encoder_initial_cell_state)\\n    decoder_input = output_batch[:,:-1]\\n    decoder_output = output_batch[:,1:]\\n    decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\\n    decoderNetwork.attention_mechanism.setup_memory(a)\\n    decoder_initial_state = decoderNetwork.build_decoder_initial_state(BATCH_SIZE,\\n                                                                       encoder_state=[a_tx, c_tx],\\n                                                                       Dtype=tf.float32)\\n    outputs, _, _ = decoderNetwork.decoder(decoder_emb_inp,initial_state=decoder_initial_state,\\n                                           sequence_length=BATCH_SIZE*[Ty-1])\\n    logits = outputs.rnn_output\\n    loss = loss_function(logits, decoder_output)\\n    return loss\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# RNN LSTM hidden and memory state initializer\\ndef initialize_initial_state():\\n    return [tf.zeros((BATCH_SIZE, rnn_units)), tf.zeros((BATCH_SIZE, rnn_units))]\\n\")), mdx(\"h2\", {\n    \"id\": \"calculating-bleu-score\"\n  }, \"Calculating BLEU Score\"), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"BLEU (bilingual evaluation understudy) is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another. Quality is considered to be the correspondence between a machine's output and that of a human: \\\"the closer a machine translation is to a professional human translation, the better it is\\\". - Wikipedia\")), mdx(\"p\", null, \"BLEU is a metric for evaluating a generated sentence to a reference sentence.\\nA perfect match results in a score of 1.0, whereas a perfect mismatch results in a score of 0.0.\"), mdx(\"p\", null, \"So now we're going to define our translation function & calculate the BLEU score for test data at\\nthe end of every epoch while training. Note that test data is sentences that our tokenizer didn't\\ntrain with, so there must be some words that our tokenizer didn't know. I'm currently working to\\nfix this issue. Based on keras Tokenizer API it have \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"oov_token\"), \" for handling this but i'm not sure.\"), mdx(\"p\", null, \"For now i'm handling this by adding \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"unk\"), \" in train dataset so the tokenizer can read it, and then\\nwhen coming to translation if there is word that our tokenizer don't know i'll set it by index of\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"unk\"), \" not very eficient but it works.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Translate\\ndef Translate(input_raw):\\n    input_raw = CP(preprocess(input_raw))\\n    input_lines = ['bos '+ input_raw + '']\\n\\n    input_sequences, unique = [], []\\n    for line in input_lines:\\n        temp = []\\n        for w in line.split(' '):\\n            try:\\n                temp.append(en_tokenizer.word_index[w])\\n            except: # Avoid Error\\n                unique.append(w)\\n                temp.append(en_tokenizer.word_index['unk'])\\n        input_sequences.append(temp)\\n\\n    input_sequences = pad_sequences(input_sequences, maxlen=Tx, padding='post')\\n    inp = tf.convert_to_tensor(input_sequences)\\n    inference_batch_size = input_sequences.shape[0]\\n    encoder_initial_cell_state = [tf.zeros((inference_batch_size, rnn_units)),\\n                                  tf.zeros((inference_batch_size, rnn_units))]\\n    encoder_emb_inp = encoderNetwork.encoder_embedding(inp)\\n    a, a_tx, c_tx = encoderNetwork.encoder_rnnlayer(encoder_emb_inp,\\n                                                    initial_state = encoder_initial_cell_state)\\n\\n    start_tokens = tf.fill([inference_batch_size], jp_tokenizer.word_index['bos'])\\n\\n    end_token = jp_tokenizer.word_index['eos']\\n\\n    greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\\n\\n    decoder_input = tf.expand_dims([jp_tokenizer.word_index['bos']] * inference_batch_size,1)\\n    decoder_emb_inp = decoderNetwork.decoder_embedding(decoder_input)\\n\\n    decoder_instance = tfa.seq2seq.BasicDecoder(cell = decoderNetwork.rnn_cell,\\n                                                sampler = greedy_sampler,\\n                                                output_layer = decoderNetwork.dense_layer)\\n    decoderNetwork.attention_mechanism.setup_memory(a)\\n\\n    decoder_initial_state = decoderNetwork.build_decoder_initial_state(\\n        inference_batch_size, encoder_state=[a_tx, c_tx], Dtype=tf.float32)\\n\\n    maximum_iterations = tf.round(tf.reduce_max(Tx) * 2)\\n\\n    decoder_embedding_matrix = decoderNetwork.decoder_embedding.variables[0]\\n    (first_finished, first_inputs,first_state) = decoder_instance.initialize(\\n        decoder_embedding_matrix, start_tokens = start_tokens,\\n        end_token = end_token, initial_state = decoder_initial_state)\\n\\n    inputs = first_inputs\\n    state = first_state\\n    predictions = np.empty((inference_batch_size,0), dtype = np.int32)\\n    for j in range(maximum_iterations):\\n        outputs, next_state, next_inputs, finished = decoder_instance.step(j, inputs,state)\\n        inputs = next_inputs\\n        state = next_state\\n        outputs = np.expand_dims(outputs.sample_id,axis = -1)\\n        predictions = np.append(predictions, outputs, axis = -1)\\n\\n    res = ''\\n    for i in range(len(predictions)):\\n        line = predictions[i,:]\\n        seq = list(itertools.takewhile(lambda index: index !=2, line))\\n        res += \\\" \\\".join( [jp_tokenizer.index_word[w] for w in seq])\\n    res = res.split()\\n\\n    # Return back Unique words\\n    for i in range(len(res)):\\n        if res[i] == 'unk' and unique != []:\\n            res[i] = unique.pop(0)\\n\\n    return ' '.join(res)\\n\\n# Calculate BLEU\\ndef BLEU(X, y):\\n    # Prediction\\n    pred = [Translate(w) for w in tqdm(X)]\\n    # Calculate BLEU\\n    score = sacrebleu.corpus_bleu(pred, [y]).score / 100\\n    return score, pred\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Custom Train Progress\\nclass Progress:\\n    def __init__(self):\\n        self.fig = plt.figure(figsize = (8,6))\\n        self.ax = self.fig.add_subplot(1, 1, 1)\\n        self.loss, self.val_loss, self.BLEU = [], [], []\\n        self.epoch_loss = 0\\n\\n    def get_val_loss(self):\\n        return [x[1] for x in self.val_loss]\\n\\n    # Plot\\n    def dynamic_plot(self):\\n        self.ax.cla()\\n        self.ax.plot(range(len(self.loss)), self.loss, label='loss')\\n        if len(self.val_loss) >= 1:\\n            x = [l[0] for l in self.val_loss]\\n            y = [l[1] for l in self.val_loss]\\n            self.ax.plot(x, y, color = 'r', label='val_loss')\\n            self.ax.plot(x, self.BLEU, color = 'purple', label='BLEU')\\n        self.ax.set_ylim(0,)\\n        self.ax.legend(loc = 1)\\n        display(self.fig)\\n\\n    # Train step progress\\n    def train_progress(self, epoch, step, steps_per_epoch, start):\\n        self.dynamic_plot()\\n        print(f'Working on Epoch {epoch}')\\n        print('[' + ('=' * int((step + 1) / steps_per_epoch * 60)).ljust(61, ' ')\\n              + f']  {step + 1}/{steps_per_epoch} - loss : {round(self.epoch_loss / step, 4)}')\\n        print(f'Time per Step {round(timeit.default_timer() - start, 2)} s')\\n\\n    def summary(self):\\n        loss = np.array_split(np.array(self.loss), len(self.val_loss))\\n        loss = [np.mean(x) for x in loss]\\n        val_loss = [x[1] for x in self.val_loss]\\n        df = pd.DataFrame({'Epochs' : range(1, len(val_loss) + 1), 'loss' : loss,\\n                           'val loss' : val_loss, 'BLEU' : self.BLEU})\\n\\n        self.dynamic_plot()\\n        clear_output(wait = True)\\n        display(df)\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Initialize Train Progress\\nTP = Progress()\\nbest_prediction = []\\n\\nfor i in range(1, epochs + 1):\\n\\n    encoder_initial_cell_state = initialize_initial_state()\\n    total_loss = 0.0\\n    # Train Loss\\n    TP.epoch_loss = 0\\n\\n    # Train\\n    for (batch , (input_batch, output_batch)) in enumerate(dataset.take(steps_per_epoch)):\\n        start = timeit.default_timer()\\n        batch_loss = train_step(input_batch, output_batch, encoder_initial_cell_state)\\n        total_loss += batch_loss\\n        TP.loss.append(batch_loss.numpy())\\n        TP.epoch_loss += batch_loss.numpy()\\n\\n        if (batch+1) % 30 == 0:\\n            TP.train_progress(i, batch, steps_per_epoch, start)\\n            clear_output(wait = True)\\n\\n    # Validitate\\n    encoderNetwork.trainable = False  # Freeze our model layer to make sure\\n    decoderNetwork.trainable = False  # it didn't learn anything from val_data\\n\\n    # Valid loss\\n    val_loss = 0\\n    for (batch, (input_batch, output_batch)) in enumerate(val_dataset.take(val_steps_per_epoch)):\\n        batch_loss = evaluate(input_batch, output_batch, encoder_initial_cell_state)\\n        val_loss += batch_loss.numpy()\\n    val_loss /= val_steps_per_epoch\\n\\n    TP.val_loss.append((i * steps_per_epoch - 1, val_loss))\\n\\n    # Bleu Score\\n    bleu_score, pred = BLEU(eng_test, jpn_test)\\n    TP.BLEU.append(bleu_score)\\n\\n    encoderNetwork.trainable = True  # Unfreeze layer for next epoch\\n    decoderNetwork.trainable = True\\n\\n    # Save best model\\n    if bleu_score == max(TP.BLEU) and val_loss == min(TP.get_val_loss()):\\n        best_prediction = pred\\n        encoderNetwork.save_weights('encoderNetwork')\\n        decoderNetwork.save_weights('decoderNetwork')\\n\\nTP.summary()\\n\")), mdx(\"table\", null, mdx(\"thead\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"thead\"\n  }, mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"Epochs\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"loss\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"val loss\"), mdx(\"th\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"BLEU\"))), mdx(\"tbody\", {\n    parentName: \"table\"\n  }, mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"1\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.755007\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.617767\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.033657\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"2\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.507803\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.467358\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.100527\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"3\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.366943\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.404535\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.169416\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"4\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.278531\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.382699\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.206622\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"5\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.220114\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.379538\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.223136\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"6\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.180076\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.384533\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.240543\")), mdx(\"tr\", {\n    parentName: \"tbody\"\n  }, mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"7\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.152284\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.390775\"), mdx(\"td\", {\n    parentName: \"tr\",\n    \"align\": \"center\"\n  }, \"0.256055\")))), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"490px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/4968cd1de5dc4c8cb3cbadd3b3801588/41d3c/output_49_1.png\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"72.78481012658227%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsSAAALEgHS3X78AAACXklEQVQ4y52RT08TQRjG9zt48SuYgISEePBuIn6HBoMaE60XPXKRqjF69WI8ATcPRk0jCUYM8k+FQOgChZZu6F/ows7u0m53d3Zn3sdsWy0NJlIneTIzyby/93mfUTKZzFXDMN6apjlpmuZUL2KMTR0Y1lShWJrQdf29pmnXlFxu7y4X+K9FAKRdR7lYRKlcBmPsoVIsFmIuFyACJ6KwF0kpQ243wqOq7hmGEQHvK9ns7qjLKQIKgIjonO46D6NDEN0ZY3GlWMiPuFz2BPz9KNqbFYQgDEOYphlX8vvaTceXkKeA/4KeAQKBEKLlMK9lRku2hJAQRB2HPYzeDazp+ZHUgUTJbjmUktqdW/Gcw203sJBL3zqqEybWIPIW6PRYv4V2g865ncvfRi6WKjFAIlWFeL0c0o90HbYTdrmQ1FKTgTPqBqqqeicaM6rT66B3qy7ezJhY2zmBrjvwTxwgSgOyrRamE01zBWEoYJosrlQqlZiUf365WVGugZIqp8nFBn1YdymVOaGVbYusQ4saVUZulRFsRjAZwYpkcDh1GLYdV9Lp9O3213blLwTgB4BWCTG9EeCzyjGT4vi07uNLysf3HR9fVR/b+z5WM77QDjm8hvVA0TQtFgQBhBBewAPumq5XNxzuGA73bdeTns8R+Bwi8Fwv4DwUvMbJK9nSNxzBNUZe5lg6xzUOix3fUxKJxMVkMnllc2uzb2lhaWDs0dj1+dn5ge3cTv+T50+H55aXBtXsXt/YeOLGys/Fwd0ttf/ls/HhjYXpocAsXXr14vGw+u3jkFHKXp6dW7jwC/SSU1VUgwWcAAAAAElFTkSuQmCC')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"png\",\n    \"title\": \"png\",\n    \"src\": \"/static/4968cd1de5dc4c8cb3cbadd3b3801588/41d3c/output_49_1.png\",\n    \"srcSet\": [\"/static/4968cd1de5dc4c8cb3cbadd3b3801588/c26ae/output_49_1.png 158w\", \"/static/4968cd1de5dc4c8cb3cbadd3b3801588/6bdcf/output_49_1.png 315w\", \"/static/4968cd1de5dc4c8cb3cbadd3b3801588/41d3c/output_49_1.png 490w\"],\n    \"sizes\": \"(max-width: 490px) 100vw, 490px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\",\n    \"decoding\": \"async\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"# Load best weights\\nencoderNetwork.load_weights('encoderNetwork')\\ndecoderNetwork.load_weights('decoderNetwork')\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb3601083d0>\\n\")), mdx(\"p\", null, \"Let's check the best prediction of our model.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"for i in range(7,16):\\n    print(\\\"English Sentence:\\\")\\n    print(eng_test[i])\\n    print(\\\"\\\\nJapanese Translation:\\\")\\n    print(best_prediction[i])\\n    print(\\\"\\\\nJapanese Reference:\\\")\\n    print(jpn_test[i])\\n    print(''.ljust(60, '-'))\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"English Sentence:\\nin september there are just a few people here and there on the beach\\n\\nJapanese Translation:\\n\\uFF19 \\u6642 \\u306B \\u306F \\u3053\\u3053 \\u306B \\u4ED6 \\u306E \\u4EBA \\u304C \\u4F4F\\u3093 \\u3067 \\u3044 \\u306A\\u3044 \\u4EBA \\u304C \\u305D\\u306E \\u30D3\\u30FC\\u30C1 \\u3067 \\u4ED6 \\u306E \\u4EBA\\u9054 \\u304C \\u6B8B\\u308A \\u306E \\u3082\\u3068 \\u3092 \\u3042\\u3061\\u3089 \\u306B \\u5EFA\\u8A2D \\u898B \\u305F\\n\\nJapanese Reference:\\n\\uFF19\\u6708 \\u306E \\u6D77 \\u306F \\u4EBA \\u304C \\u307E\\u3070\\u3089 \\u3060 \\u306D\\n------------------------------------------------------------\\nEnglish Sentence:\\nwhile you are young you should read a lot\\n\\nJapanese Translation:\\n\\u82E5\\u3044 \\u9803 \\u306F \\u8AAD\\u307F \\u7D42\\u308F\\u3063 \\u305F\\u3089 \\u3044\\u3044 \\u3088\\n\\nJapanese Reference:\\n\\u82E5\\u3044 \\u3046\\u3061 \\u306B \\u305F\\u304F\\u3055\\u3093 \\u306E \\u672C \\u3092 \\u8AAD\\u3080 \\u3079\\u304D \\u3060\\n------------------------------------------------------------\\nEnglish Sentence:\\nhere i come\\n\\nJapanese Translation:\\n\\u3053\\u3053 \\u306B \\u6765 \\u305F \\u306E\\n\\nJapanese Reference:\\n\\u3044\\u307E \\u884C\\u304D \\u307E\\u3059\\n------------------------------------------------------------\\nEnglish Sentence:\\nonce you have decided when you will be coming let me know\\n\\nJapanese Translation:\\n\\u6765\\u308B \\u304B \\u541B \\u306B \\u306F \\u9023\\u7D61 \\u3092 \\u8A00\\u3063 \\u3066 \\u304D \\u305F \\u3088\\n\\nJapanese Reference:\\n\\u3044\\u3064 \\u6765\\u308B \\u304B \\u6C7A\\u307E\\u3063 \\u305F\\u3089 \\u6559\\u3048 \\u3066\\n------------------------------------------------------------\\nEnglish Sentence:\\nhe jumped on the train\\n\\nJapanese Translation:\\n\\u5F7C \\u306F \\u96FB\\u8ECA \\u306B \\u65D7 \\u3092 \\u98DB\\u3073\\u8D8A\\u3048 \\u305F\\n\\nJapanese Reference:\\n\\u5F7C \\u306F \\u96FB\\u8ECA \\u306B \\u98DB\\u3073\\u4E57\\u3063 \\u305F\\n------------------------------------------------------------\\nEnglish Sentence:\\nhe passed away yesterday\\n\\nJapanese Translation:\\n\\u5F7C \\u306F \\u6628\\u65E5 \\u4EA1\\u304F\\u306A\\u3063 \\u305F\\n\\nJapanese Reference:\\n\\u5F7C \\u306F \\u6628\\u65E5 \\u304A \\u4EA1\\u304F\\u306A\\u308A \\u306B \\u306A\\u308A \\u307E\\u3057 \\u305F\\n------------------------------------------------------------\\nEnglish Sentence:\\ni had no other choice\\n\\nJapanese Translation:\\n\\u4ED6 \\u306B \\u9078\\u629E\\u80A2 \\u304C \\u306A\\u304B\\u3063 \\u305F\\n\\nJapanese Reference:\\n\\u4ED6 \\u306B \\u624B \\u304C \\u306A\\u304B\\u3063 \\u305F \\u306E \\u3060\\n------------------------------------------------------------\\nEnglish Sentence:\\nare you good at bowling\\n\\nJapanese Translation:\\n\\u30DC\\u30FC\\u30EA\\u30F3\\u30B0 \\u306F \\u5F97\\u610F \\u3067\\u3059 \\u304B\\n\\nJapanese Reference:\\n\\u30DC\\u30A6\\u30EA\\u30F3\\u30B0 \\u306F \\u5F97\\u610F\\n------------------------------------------------------------\\nEnglish Sentence:\\nit is strange that you do not know anything about that matter\\n\\nJapanese Translation:\\n\\u305D\\u308C \\u306B\\u3064\\u3044\\u3066 \\u4F55 \\u3082 \\u77E5\\u3089 \\u306A\\u3044 \\u3053\\u3068 \\u304C \\u306A\\u3044 \\u3068\\u3044\\u3046 \\u3053\\u3068 \\u306F \\u5909 \\u3060\\n\\nJapanese Reference:\\n\\u3042\\u306A\\u305F \\u304C \\u305D\\u306E \\u3053\\u3068 \\u306B\\u3064\\u3044\\u3066 \\u4F55 \\u3082 \\u77E5\\u3089 \\u306A\\u3044 \\u306E \\u306F \\u5909 \\u3060\\n------------------------------------------------------------\\n\")), mdx(\"h2\", {\n    \"id\": \"test-with-some-raw-input\"\n  }, \"Test with Some Raw Input\"), mdx(\"p\", null, \"Yeay now let's play with \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"our\"), \" Machine Translation with some raw input. We'll cross check the\\nprediction from MT with Google Translate API to translate it back to english and see how\\nbad \", mdx(\"strong\", {\n    parentName: \"p\"\n  }, \"our\"), \" MT is :).\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"from googletrans import Translator\\n# Google Translate\\ntranslator = Translator()\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"raw_input = ['i love you', 'i am sorry', 'hello', 'thank you',\\n             'is there something i can help?']\\n\\nfor i in range(len(raw_input)):\\n    prediction = Translate(raw_input[i])\\n    print(\\\"English Sentence:\\\")\\n    print(raw_input[i])\\n    print(\\\"\\\\nJapanese Translation:\\\")\\n    print(prediction)\\n    print(\\\"\\\\nEnglish Translation from prediction [GoogleTranslate]:\\\")\\n    print(translator.translate(prediction).text)\\n    print(''.ljust(60, '-'))\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\"\n  }, \"English Sentence:\\ni love you\\n\\nJapanese Translation:\\n\\u611B\\u3057 \\u3066\\u308B \\u3088\\n\\nEnglish Translation from prediction [GoogleTranslate]:\\nI love you\\n------------------------------------------------------------\\nEnglish Sentence:\\ni am sorry\\n\\nJapanese Translation:\\n\\u3059\\u307F\\u307E\\u305B\\u3093\\n\\nEnglish Translation from prediction [GoogleTranslate]:\\nExcuse me\\n------------------------------------------------------------\\nEnglish Sentence:\\nhello\\n\\nJapanese Translation:\\n\\u3082\\u3057\\u3082\\u3057\\n\\nEnglish Translation from prediction [GoogleTranslate]:\\nHello\\n------------------------------------------------------------\\nEnglish Sentence:\\nthank you\\n\\nJapanese Translation:\\n\\u3042\\u308A\\u304C\\u3068\\u3046 \\u3054\\u3056\\u3044 \\u307E\\u3059\\n\\nEnglish Translation from prediction [GoogleTranslate]:\\nThank you\\n------------------------------------------------------------\\nEnglish Sentence:\\nis there something i can help?\\n\\nJapanese Translation:\\n\\u4F55 \\u304B \\u624B\\u4F1D\\u3048\\u308B \\u3082\\u306E \\u304C \\u3042\\u308B \\u306E\\n\\nEnglish Translation from prediction [GoogleTranslate]:\\nThere is something to help\\n------------------------------------------------------------\\n\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-python\"\n  }, \"import pickle\\n\\nwith open('en_tokenizer.pickle', 'wb') as handle:\\n    pickle.dump(en_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\\nhandle.close()\\n\\nwith open('jp_tokenizer.pickle', 'wb') as handle:\\n    pickle.dump(jp_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\\nhandle.close()\\n\")), mdx(\"h2\", {\n    \"id\": \"reference\"\n  }, \"Reference\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"TensorFlow Addons Networks : Sequence-to-Sequence NMT with Attention Mechanism \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt\"\n  }, \"Link\")), mdx(\"li\", {\n    parentName: \"ol\"\n  }, \"seq2seq (Sequence to Sequence) Model for Deep Learning with PyTorch \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.guru99.com/seq2seq-model.html\"\n  }, \"Link\"))));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Machine Translation English to Japanese with Seq2Seq & Tensorflow","tags":"nlp, nmt, tensorflow, seq2seq, python","date":"August 19, 2020","description":"Machine Translation English to Japanese using Seq2Seq & Tensorflow 2"},"tableOfContents":{"items":[{"url":"#overview","title":"Overview"},{"url":"#install-some-tools","title":"Install some tools"},{"url":"#dataset","title":"Dataset"},{"url":"#text-preprocessing","title":"Text Preprocessing"},{"url":"#word-tokenizing","title":"Word Tokenizing"},{"url":"#word-cloud","title":"Word Cloud"},{"url":"#build--train-model","title":"Build & Train Model"},{"url":"#calculating-bleu-score","title":"Calculating BLEU Score"},{"url":"#test-with-some-raw-input","title":"Test with Some Raw Input"},{"url":"#reference","title":"Reference"}]}},"previous":null,"next":{"fields":{"slug":"/cnn-keras-cv-0-996-tpu/"},"frontmatter":{"title":"MNIST Digit Classifier Using Keras, Tensorflow, and TPU"}}},"pageContext":{"id":"a36bb6fb-4781-55a5-bedd-1072d52d7875","previousPostId":null,"nextPostId":"7b5032f1-99d9-5c6f-aa7c-01d1af58e8eb"}},
    "staticQueryHashes": ["1503043946","3274528899","3764592887"]}